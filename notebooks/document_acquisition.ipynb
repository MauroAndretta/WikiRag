{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire Wikipidia Pages\n",
    "\n",
    "## Overview \n",
    "\n",
    "Acquire the wikipedia pages information and save it locally, then chunks them and loads on the Qdrant DB. \n",
    "\n",
    "All the wikipiedia information are acquired using the `wikipedia_urls.txt` file, which conatis the list of Wikipedia links from which the information will be taken from. \n",
    "\n",
    "# Prerequisistes\n",
    "\n",
    "A conda environment is needed. \n",
    "\n",
    "For example: \n",
    "```\n",
    "cd path/to/conda/dir\n",
    "conda env create -f wiki_rag_notebooks.yaml\n",
    "conda activate wiki_rag_notebooks\n",
    "python -m ipykernel install --user --name wiki_rag_notebooks --display-name \"wiki_rag_notebooks\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libraries\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "from urllib.parse import unquote, urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test wikipediaapi library\n",
    "\n",
    "Repo [here](https://github.com/martin-majlis/Wikipedia-API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Wikipedia API\n",
    "wiki_wiki = wikipediaapi.Wikipedia(\n",
    "    'WikiRag (mauo.andretta222@gmail.com)', \n",
    "    'it',\n",
    "    extract_format=wikipediaapi.ExtractFormat.WIKI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://it.wikipedia.org/wiki/Giochi_olimpici',\n",
       " 'https://it.wikipedia.org/wiki/Giochi_olimpici_estivi']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to read Wikipedia page titles from an external file\n",
    "def load_wikipedia_urls(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        urls = [line.strip() for line in file.readlines()]\n",
    "    return urls\n",
    "\n",
    "urls = load_wikipedia_urls('../wikipedia_urls.txt')\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Giochi_olimpici', 'Giochi_olimpici_estivi']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract the title from a Wikipedia URL\n",
    "def get_title_from_url(url):\n",
    "    path = urlparse(url).path\n",
    "    title = path.split('/')[-1]\n",
    "    return unquote(title)\n",
    "\n",
    "# List with all the Wikipedia page titles\n",
    "titles = [get_title_from_url(url) for url in urls]\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia content: I Giochi olimpici dell'era moderna sono un evento sportivo quadriennale che prevede la competizione \n",
      "Wikipedia title: Giochi olimpici\n",
      "Wikipedia URL: https://it.wikipedia.org/wiki/Giochi_olimpici\n",
      "Wikipedia language: it\n"
     ]
    }
   ],
   "source": [
    "# Function to get the Wikipedia page content\n",
    "p_wiki = wiki_wiki.page(titles[0])\n",
    "# Print the content of the Wikipedia page\n",
    "print(f\"Wikipedia content: {p_wiki.text[:100]}\")\n",
    "# Print the Wikipedia page title\n",
    "print(f\"Wikipedia title: {p_wiki.title}\")\n",
    "# Print the Wikipedia page URL\n",
    "print(f\"Wikipedia URL: {p_wiki.fullurl}\")\n",
    "# Print the Wikipedia language\n",
    "print(f\"Wikipedia language: {p_wiki.language}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*: Storia - \n",
      "**: Antichità - I primi giochi olimpici si svolsero nel \n",
      "**: La rinascita dei Giochi olimpici - La memoria degli antichi Giochi olimpici\n",
      "*: Interferenze con le Olimpiadi - \n",
      "**: Guerra - Contrariamente alle speranze del barone \n",
      "**: Politica - La politica interferì sullo svolgimento \n",
      "**: Pandemia di COVID-19 - Il 24 marzo 2020 è stato annunciato il r\n",
      "*: Il Comitato olimpico internazionale - Il Movimento Olimpico racchiude tutte qu\n",
      "**: Contestazioni al CIO - Il CIO è stato più volte oggetto di cont\n",
      "*: Simboli olimpici - Il movimento olimpico utilizza diversi s\n",
      "*: Cerimonie - \n",
      "**: Cerimonia di apertura - La cerimonia di apertura di un'Olimpiade\n",
      "**: Cerimonia di chiusura - La cerimonia di chiusura è più semplice \n",
      "**: Consegna delle medaglie - Al termine di ogni evento olimpico si ti\n",
      "*: Sport olimpici - Ai Giochi di Sydney 2000 erano presenti \n",
      "**: Competizioni artistiche - L'inserimento delle competizioni d'arte \n",
      "*: Doping - Già dagli inizi del XX secolo si iniziar\n",
      "*: Atleti olimpici - \n",
      "**: Dilettanti e professionisti - Secondo de Coubertin gli atleti non dove\n",
      "**: Campioni olimpici e medagliati - Ai Giochi olimpici viene stilata una cla\n",
      "**: Atleti a medaglia in due differenti sport - Questa lista è suscettibile di variazion\n",
      "**: Atleti sia olimpici sia paralimpici - Alcuni atleti hanno gareggiato sia ai Gi\n",
      "*: Edizioni dell'era moderna - La tabella seguente riporta tutte le edi\n",
      "*: Film ufficiali dei Giochi olimpici - Nel maggio 2000 il CIO ha annunciato di \n",
      "*: Note - \n",
      "*: Bibliografia - Emanuela Audisio, Tutti i cerchi del mon\n",
      "*: Voci correlate - \n",
      "*: Altri progetti - Wikiquote contiene citazioni sui giochi \n",
      "*: Collegamenti esterni - \n",
      "(EN) Sito ufficiale, su olympics.com. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_sections(sections, level=0):\n",
    "    for s in sections:\n",
    "            print(\"%s: %s - %s\" % (\"*\" * (level + 1), s.title, s.text[0:40]))\n",
    "            print_sections(s.sections, level + 1)\n",
    "\n",
    "print_sections(p_wiki.sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Acquiring the Wikipedia Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://it.wikipedia.org/wiki/Giochi_olimpici',\n",
       " 'https://it.wikipedia.org/wiki/Giochi_olimpici_estivi']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to read Wikipedia page titles from an external file\n",
    "def load_wikipedia_urls(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        urls = [line.strip() for line in file.readlines()]\n",
    "    return urls\n",
    "\n",
    "urls = load_wikipedia_urls('../wikipedia_urls.txt')\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Giochi_olimpici', 'Giochi_olimpici_estivi']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract the title from a Wikipedia URL\n",
    "def get_title_from_url(url):\n",
    "    path = urlparse(url).path\n",
    "    title = path.split('/')[-1]\n",
    "    return unquote(title)\n",
    "\n",
    "# List with all the Wikipedia page titles\n",
    "titles = [get_title_from_url(url) for url in urls]\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell code used to clean the text\n",
    "\n",
    "# Function to clean the text\n",
    "# usefult url to text processing: https://stackoverflow.com/questions/72214118/preprocessing-data-to-remove-italian-stopwords-for-text-analysis\n",
    "def clean_text(text):\n",
    "    # Remove references (e.g., [1], [2])\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "    # Remove hyperlinks\n",
    "    text = re.sub(r'https?:\\/\\/.*\\/\\w*', '', text)\n",
    "    # Remove words with less than 2 characters\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b', '', text)\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # Remove whitespace (including new line characters)\n",
    "    text = re.sub(r'\\s\\s+', ' ', text).strip()\n",
    "    # To lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of usage of the function clean_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"\n",
    "This is a sample text with various elements that need to be cleaned.\n",
    "\n",
    "Here is a reference [1] that should be removed.\n",
    "\n",
    "We should also remove this hyperlink: https://example.com/page and any short words like \"a\", \"is\", \"to\".\n",
    "\n",
    "Furthermore, punctuation, such as commas, periods, and exclamation marks, should be removed!\n",
    "\n",
    "This is the \"See also\" section that should be excluded.\n",
    "\n",
    "References:\n",
    "[2] Another reference to remove.\n",
    "External links:\n",
    "[3] And another.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this sample text with various elements that need cleaned here reference that should removed should also remove this hyperlink and any short words like furthermore punctuation such commas periods and exclamation marks should removed this the see also section that should excluded references another reference remove external links and another'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the clean_text function\n",
    "cleaned_text = clean_text(test_text)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the wikipediaapi object from a Wikipedia Page Title\n",
    "def scrape_wikipedia(title):\n",
    "\n",
    "    p_wiki = wiki_wiki.page(title)\n",
    "           \n",
    "    return p_wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to get a dictionary with the sections of a Wikipedia page\n",
    "def get_sections_dict(sections):\n",
    "    section_dict = {}\n",
    "    for section in sections:\n",
    "        section_dict[section.title] = clean_text(section.text)\n",
    "        # Recursively add subsections\n",
    "        if section.sections:\n",
    "            section_dict.update(get_sections_dict(section.sections))\n",
    "    return section_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giochi_olimpici (36334 characters, language: it)\n",
      "Giochi_olimpici_estivi (14208 characters, language: it)\n"
     ]
    }
   ],
   "source": [
    "# Scrape the content from each URL\n",
    "documents = {}\n",
    "for title in titles:\n",
    "    p_wiki = scrape_wikipedia(title)\n",
    "    documents[title] = {\n",
    "        'title': p_wiki.title,\n",
    "        'url': p_wiki.fullurl,\n",
    "        'language': p_wiki.language,\n",
    "        'content': clean_text(p_wiki.text),\n",
    "        #'sections': get_sections_dict(p_wiki.sections),\n",
    "    }\n",
    "\n",
    "# Check the content length ang language for all the documents\n",
    "for title, doc in documents.items():\n",
    "    print(f'{title} ({len(doc[\"content\"])} characters, language: {doc[\"language\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snippet from Giochi_olimpici:\n",
      "giochi olimpici dell era moderna sono evento sportivo quadriennale che prevede competizione tra migliori atleti del mondo quasi tutte discipline sportive praticate nei cinque continenti abitati essi pur essendo comunemente chiamati anche olimpiadi non sono confondere con olimpiade quest ultima indica intervallo tempo quattro anni che intercorre tra edizione dei giochi olimpici estivi successiva per questo anche giochi del 1916 1940 1944 non sono stati disputati continuato conteggiare olimpiadi c\n",
      "\n",
      "Snippet from Giochi_olimpici_estivi:\n",
      "giochi olimpici estivi sono una manifestazione sportiva multidisciplinare internazionale prevista negli anni multipli organizzata dal comitato olimpico internazionale olimpiadi sono più prestigioso mondo tra gli eventi questo tipo presentano una varietà sport superiore quella altre manifestazioni simili tutti gli sport vittoria olimpica viene generalmente considerata come risultato più prestigioso conseguibile qualsiasi sport eccezione del calcio pochi altri sport prevalentemente squadra per qua\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a snippet of the cleaned text\n",
    "for title, document in documents.items():\n",
    "    print(f\"Snippet from {title}:\\n{document['content'][:500]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the sections of the first document\n",
    "for section, text in documents[titles[0]]['sections'].items():\n",
    "    print(f\"Section: {section}\\n{text[:500]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giochi_olimpici: False\n",
      "Giochi_olimpici_estivi: False\n"
     ]
    }
   ],
   "source": [
    "# check if a string representing an external link exist in the content\n",
    "def has_external_urls(content):\n",
    "    return 'https' in content\n",
    "\n",
    "# Check if the content has an image\n",
    "for title, document in documents.items():\n",
    "    print(f\"{title}: {has_external_urls(document['content'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Tokenization\n",
    "\n",
    "Tokenize the cleaned text.\n",
    "\n",
    "1. Stop words removal: Stop words are simply those words that are extremely common in all sorts of texts and probably bear no (or only a little) useful information \n",
    "\n",
    "2. Tokenization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Mauro\n",
      "[nltk_data]     Andretta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Mauro\n",
      "[nltk_data]     Andretta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mauro\n",
      "[nltk_data]     Andretta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dowlnoad the stopwords \n",
    "nltk.download('punkt', force=True)\n",
    "nltk.download('punkt_tab', force=True)\n",
    "nltk.download('stopwords', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to tokenize and remove stopwords from a text\n",
    "def remove_stopwords(content, language):\n",
    "    # Get the stopwords for the specified language\n",
    "    if language == 'en':\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "    elif language == 'it':\n",
    "        stop_words = set(stopwords.words('italian'))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported language: {language}\")\n",
    "        \n",
    "    # Tokenize the content\n",
    "    tokens = word_tokenize(content)\n",
    "    \n",
    "    # Remove the stopwords\n",
    "    filtered_content = [token for token in tokens if token.lower() not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the stopwords from the content and tokenize it\n",
    "for title, document in documents.items():\n",
    "    documents[title]['content'] = remove_stopwords(document['content'], document['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snippet from Giochi_olimpici:\n",
      "giochi olimpici moderna evento sportivo quadriennale prevede competizione migliori atleti mondo quasi tutte discipline sportive praticate cinque continenti abitati essi pur comunemente chiamati olimpiadi confondere olimpiade quest ultima indica intervallo tempo quattro anni intercorre edizione giochi olimpici estivi successiva giochi 1916 1940 1944 stati disputati continuato conteggiare olimpiadi cosicché giochi parigi 2024 stati trentatreesima edizione nome giochi olimpici stato scelto ricordar\n",
      "\n",
      "Snippet from Giochi_olimpici_estivi:\n",
      "giochi olimpici estivi manifestazione sportiva multidisciplinare internazionale prevista anni multipli organizzata comitato olimpico internazionale olimpiadi prestigioso mondo eventi tipo presentano varietà sport superiore altre manifestazioni simili sport vittoria olimpica viene generalmente considerata risultato prestigioso conseguibile qualsiasi sport eccezione calcio pochi altri sport prevalentemente squadra quali vengono disputati campionati mondiali riscuotono grande successo conquista tit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a snippet of the cleaned text\n",
    "for title, document in documents.items():\n",
    "    print(f\"Snippet from {title}:\\n{document['content'][:500]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Storage\n",
    "\n",
    "After the tokenization is it possible to store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document for 'Giochi_olimpici' saved as 'wikipedia_documents\\Giochi_olimpici.json'\n",
      "Document for 'Giochi_olimpici_estivi' saved as 'wikipedia_documents\\Giochi_olimpici_estivi.json'\n"
     ]
    }
   ],
   "source": [
    "# Directory where the JSON files will be stored\n",
    "output_dir = 'wikipedia_documents'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save each document in an individual JSON file\n",
    "for title, doc in documents.items():\n",
    "    # Sanitize title to create a valid filename\n",
    "    filename = f\"{title.replace(' ', '_').replace('/', '_')}.json\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    # Write the document to a JSON file\n",
    "    with open(filepath, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(doc, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Document for '{title}' saved as '{filepath}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create chunks\n",
    "\n",
    "Once the .json document are created is it possible to start chunking the individual text. \n",
    "\n",
    "The expected chunk schema should be: \n",
    "\n",
    "{\n",
    "\n",
    "    \"id\": uuid.uuid() #vector in vector db\n",
    "    \"vector\": List[float] # The embedding of the chunk\n",
    "    \"payload\": {\n",
    "\n",
    "        \"content\": str # the textual content of the chunk,\n",
    "        \"language\": str # the language of the text,\n",
    "        \"title\": str # the title of the wikipedia page,\n",
    "        \"url\": str # the url link used to get the wikipedia informations\n",
    "    }\n",
    "}\n",
    "\n",
    "Sentence transformer installation problem: [solution](https://stackoverflow.com/questions/78808745/the-python-module-sentence-transformers-is-not-found-even-though-the-package-is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents(input_dir: str):\n",
    "    # Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "    \n",
    "    # Initialize the embedding model\n",
    "    embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # List to hold all the chunks\n",
    "    all_chunks = []\n",
    "    \n",
    "    # Iterate over all JSON files in the directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(input_dir, filename)\n",
    "            \n",
    "            with open(filepath, 'r', encoding='utf-8') as json_file:\n",
    "                doc = json.load(json_file)\n",
    "                \n",
    "                # Extract the necessary information\n",
    "                title = doc['title']\n",
    "                content = doc['content']\n",
    "                language = doc['language']\n",
    "                url = doc['url']\n",
    "                \n",
    "                # Split the content into chunks\n",
    "                texts = text_splitter.split_text(content)\n",
    "                \n",
    "                # Create embeddings for each chunk using LangChain\n",
    "                embeddings = embedding_model.encode(texts)\n",
    "                \n",
    "                # Create a chunk for each piece of text\n",
    "                for i, (text, vector) in enumerate(zip(texts, embeddings)):\n",
    "                    chunk = {\n",
    "                        \"id\": str(uuid.uuid4()),  # Unique identifier\n",
    "                        \"vector\": vector.tolist(),  # Convert NumPy array to list\n",
    "                        \"payload\": {\n",
    "                            \"content\": text,\n",
    "                            \"language\": language,\n",
    "                            \"title\": title,\n",
    "                            \"url\": url,\n",
    "                        }\n",
    "                    }\n",
    "                    all_chunks.append(chunk)\n",
    "    \n",
    "    return all_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mauro Andretta\\anaconda3\\envs\\wiki_rag_notebooks\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_dir = 'wikipedia_documents'\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "chunks = process_documents(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '9bcca9b1-76dd-4597-9ecd-7aae8e62d085',\n",
       " 'vector': [-0.0050218962132930756,\n",
       "  0.03419070690870285,\n",
       "  -0.045247167348861694,\n",
       "  -0.0019858398009091616,\n",
       "  -0.11844921112060547,\n",
       "  0.03562400862574577,\n",
       "  0.03216155990958214,\n",
       "  0.067304328083992,\n",
       "  -0.06848309189081192,\n",
       "  0.06326217204332352,\n",
       "  0.06979662925004959,\n",
       "  -0.013670475222170353,\n",
       "  0.020547524094581604,\n",
       "  0.02239847369492054,\n",
       "  -0.00953915249556303,\n",
       "  -0.03514229878783226,\n",
       "  0.010729718953371048,\n",
       "  0.009665064513683319,\n",
       "  -0.09331295639276505,\n",
       "  -0.05155130475759506,\n",
       "  0.0034140448551625013,\n",
       "  -0.029114410281181335,\n",
       "  0.01524844579398632,\n",
       "  0.037869472056627274,\n",
       "  -0.13054262101650238,\n",
       "  0.0058988528326153755,\n",
       "  -0.06963079422712326,\n",
       "  0.004497836343944073,\n",
       "  -0.018714364618062973,\n",
       "  0.007497597485780716,\n",
       "  0.013199086301028728,\n",
       "  0.08543937653303146,\n",
       "  0.05496099591255188,\n",
       "  0.02430768869817257,\n",
       "  0.02171754650771618,\n",
       "  0.007798492908477783,\n",
       "  -0.04191609099507332,\n",
       "  -0.053675610572099686,\n",
       "  -0.032413508743047714,\n",
       "  0.0766717791557312,\n",
       "  -0.055454105138778687,\n",
       "  -0.0831197127699852,\n",
       "  -0.065141960978508,\n",
       "  -0.07015503942966461,\n",
       "  0.020267514511942863,\n",
       "  0.008851894177496433,\n",
       "  -0.0032134659122675657,\n",
       "  0.034095704555511475,\n",
       "  0.029397863894701004,\n",
       "  -0.010967681184411049,\n",
       "  -0.09169261902570724,\n",
       "  -0.03658004105091095,\n",
       "  0.009524459950625896,\n",
       "  -0.04793901741504669,\n",
       "  0.05181035399436951,\n",
       "  -0.06158563867211342,\n",
       "  -0.047776054590940475,\n",
       "  -0.030712472274899483,\n",
       "  -0.05457257479429245,\n",
       "  0.022551599889993668,\n",
       "  0.04927918687462807,\n",
       "  0.03344329819083214,\n",
       "  -0.031616128981113434,\n",
       "  0.015261176973581314,\n",
       "  -0.05987517163157463,\n",
       "  -0.017393585294485092,\n",
       "  -0.0754362940788269,\n",
       "  -0.07457782328128815,\n",
       "  0.01988960988819599,\n",
       "  -0.0039917584508657455,\n",
       "  0.15456919372081757,\n",
       "  -0.08601801842451096,\n",
       "  -0.04853934422135353,\n",
       "  0.019418353214859962,\n",
       "  -0.045279230922460556,\n",
       "  0.017381759360432625,\n",
       "  0.020055564120411873,\n",
       "  0.03446212410926819,\n",
       "  0.042390841990709305,\n",
       "  -0.11358778923749924,\n",
       "  0.012010021135210991,\n",
       "  -0.0006786879384890199,\n",
       "  0.0322360098361969,\n",
       "  -0.02541171759366989,\n",
       "  0.05176028981804848,\n",
       "  0.028614962473511696,\n",
       "  0.01699698343873024,\n",
       "  0.006246894132345915,\n",
       "  0.07656997442245483,\n",
       "  0.04072946310043335,\n",
       "  -0.018266525119543076,\n",
       "  0.047058045864105225,\n",
       "  -0.0660824254155159,\n",
       "  -0.026878952980041504,\n",
       "  0.09447362273931503,\n",
       "  -0.0103397686034441,\n",
       "  -0.018442073836922646,\n",
       "  -0.0889664739370346,\n",
       "  -0.006135083269327879,\n",
       "  0.011188368313014507,\n",
       "  0.03341042250394821,\n",
       "  -0.08565835654735565,\n",
       "  -0.017598198726773262,\n",
       "  0.01612509787082672,\n",
       "  -0.1184510663151741,\n",
       "  0.01232506986707449,\n",
       "  0.06483995914459229,\n",
       "  0.009074410423636436,\n",
       "  -0.03486006334424019,\n",
       "  0.1340661346912384,\n",
       "  -0.05154795944690704,\n",
       "  -0.039429981261491776,\n",
       "  -0.031011004000902176,\n",
       "  -0.054024141281843185,\n",
       "  -0.0845613181591034,\n",
       "  0.07988948374986649,\n",
       "  -0.0481451116502285,\n",
       "  -0.024081092327833176,\n",
       "  -0.0048189908266067505,\n",
       "  -0.02110368385910988,\n",
       "  0.03716333210468292,\n",
       "  -0.06864409893751144,\n",
       "  0.01645527221262455,\n",
       "  -0.030288930982351303,\n",
       "  0.0008794923196546733,\n",
       "  0.020679814741015434,\n",
       "  0.10244166851043701,\n",
       "  1.780661030081473e-32,\n",
       "  -0.09951134771108627,\n",
       "  -0.1061163991689682,\n",
       "  -0.02994684688746929,\n",
       "  0.046212706714868546,\n",
       "  -0.06736443191766739,\n",
       "  0.009279885329306126,\n",
       "  -0.029536595568060875,\n",
       "  -0.07410546392202377,\n",
       "  0.04175146296620369,\n",
       "  -0.11400789022445679,\n",
       "  -0.05831708759069443,\n",
       "  -0.02449648268520832,\n",
       "  -0.01149242278188467,\n",
       "  -0.01904825121164322,\n",
       "  0.09886109828948975,\n",
       "  -0.030284233391284943,\n",
       "  0.053583674132823944,\n",
       "  -0.011951364576816559,\n",
       "  0.01827392727136612,\n",
       "  0.03224978223443031,\n",
       "  0.006491489242762327,\n",
       "  -0.07212603092193604,\n",
       "  0.01958959922194481,\n",
       "  -0.0857054591178894,\n",
       "  0.007194965612143278,\n",
       "  0.05759834870696068,\n",
       "  -0.07221713662147522,\n",
       "  -0.09492635726928711,\n",
       "  -0.0494365319609642,\n",
       "  0.0351349376142025,\n",
       "  0.1365748941898346,\n",
       "  -0.023780878633260727,\n",
       "  -0.05625733733177185,\n",
       "  -0.10841159522533417,\n",
       "  -0.08687827736139297,\n",
       "  -0.009847025386989117,\n",
       "  0.011722549796104431,\n",
       "  -0.06441032886505127,\n",
       "  -0.026581576094031334,\n",
       "  -0.01384145300835371,\n",
       "  0.02434236742556095,\n",
       "  -0.0516413114964962,\n",
       "  0.0048835910856723785,\n",
       "  -0.014366848394274712,\n",
       "  0.058363936841487885,\n",
       "  0.022880978882312775,\n",
       "  0.02737647294998169,\n",
       "  0.011454382911324501,\n",
       "  0.07346636801958084,\n",
       "  -0.014073261991143227,\n",
       "  0.016483016312122345,\n",
       "  0.03885043412446976,\n",
       "  0.029656991362571716,\n",
       "  -0.0803641751408577,\n",
       "  0.06727515906095505,\n",
       "  0.07574529945850372,\n",
       "  -0.07100354880094528,\n",
       "  -0.008978454396128654,\n",
       "  -0.03922003135085106,\n",
       "  -0.002105075865983963,\n",
       "  -0.004072708077728748,\n",
       "  0.03032267838716507,\n",
       "  0.004902526270598173,\n",
       "  -0.010986101813614368,\n",
       "  0.011118520982563496,\n",
       "  -0.030943579971790314,\n",
       "  -0.004515893757343292,\n",
       "  -0.0271853469312191,\n",
       "  0.004344110377132893,\n",
       "  0.03121916577219963,\n",
       "  -0.02625768817961216,\n",
       "  -0.11123119294643402,\n",
       "  -0.020991133525967598,\n",
       "  0.006318923085927963,\n",
       "  0.01627465710043907,\n",
       "  -0.004329180344939232,\n",
       "  0.05444953218102455,\n",
       "  0.042478177696466446,\n",
       "  0.006504100281745195,\n",
       "  -0.002414167392998934,\n",
       "  -0.0011489130556583405,\n",
       "  0.01773173175752163,\n",
       "  -0.033099766820669174,\n",
       "  -0.03654181957244873,\n",
       "  0.0684971809387207,\n",
       "  0.06528971344232559,\n",
       "  0.05886658653616905,\n",
       "  0.04207514598965645,\n",
       "  0.0727260485291481,\n",
       "  0.08994273841381073,\n",
       "  -0.05459845811128616,\n",
       "  0.04845939204096794,\n",
       "  -0.06019357591867447,\n",
       "  0.032596245408058167,\n",
       "  0.03482101112604141,\n",
       "  -2.1222329459339484e-32,\n",
       "  -0.015122071839869022,\n",
       "  0.0038998210802674294,\n",
       "  -0.007264107931405306,\n",
       "  0.05433676764369011,\n",
       "  0.021437693387269974,\n",
       "  -0.03200189769268036,\n",
       "  -0.08811576664447784,\n",
       "  -0.06432881951332092,\n",
       "  0.06535010039806366,\n",
       "  -0.04338302090764046,\n",
       "  -0.014441176317632198,\n",
       "  -0.057958781719207764,\n",
       "  0.06392230093479156,\n",
       "  0.006876538507640362,\n",
       "  -0.044267214834690094,\n",
       "  0.005980310495942831,\n",
       "  -0.049557603895664215,\n",
       "  0.036041390150785446,\n",
       "  0.006510112900286913,\n",
       "  0.07149992138147354,\n",
       "  0.022453458979725838,\n",
       "  0.0007553239702247083,\n",
       "  -0.00430856691673398,\n",
       "  -0.11162199825048447,\n",
       "  -0.09093862026929855,\n",
       "  0.016388826072216034,\n",
       "  -0.03406780585646629,\n",
       "  -0.03149870038032532,\n",
       "  -0.054689787328243256,\n",
       "  0.00854187086224556,\n",
       "  -0.010012547485530376,\n",
       "  -0.0054214163683354855,\n",
       "  -0.04219869151711464,\n",
       "  0.05912536010146141,\n",
       "  -0.003988067619502544,\n",
       "  0.024519681930541992,\n",
       "  0.06845571845769882,\n",
       "  -0.05714467540383339,\n",
       "  -0.07091300189495087,\n",
       "  -0.025129329413175583,\n",
       "  -0.010229721665382385,\n",
       "  0.039152178913354874,\n",
       "  0.09667125344276428,\n",
       "  0.004232270177453756,\n",
       "  -0.03130991756916046,\n",
       "  -0.04913977161049843,\n",
       "  -0.023813996464014053,\n",
       "  -0.023980658501386642,\n",
       "  -0.055316682904958725,\n",
       "  -0.045421846210956573,\n",
       "  0.0603947713971138,\n",
       "  0.08392684906721115,\n",
       "  -0.03263489156961441,\n",
       "  -0.013486053794622421,\n",
       "  0.06760302186012268,\n",
       "  0.021573305130004883,\n",
       "  -0.02829904295504093,\n",
       "  -0.12973839044570923,\n",
       "  -0.13199403882026672,\n",
       "  -0.025925738736987114,\n",
       "  0.01700201816856861,\n",
       "  0.01250727940350771,\n",
       "  -0.04988015070557594,\n",
       "  0.048200443387031555,\n",
       "  0.08157529681921005,\n",
       "  0.003745305584743619,\n",
       "  -0.06093144789338112,\n",
       "  0.04929831251502037,\n",
       "  -0.02012433297932148,\n",
       "  -0.04976629838347435,\n",
       "  -0.050159331411123276,\n",
       "  -0.013736563734710217,\n",
       "  -0.04490620270371437,\n",
       "  0.053868260234594345,\n",
       "  -0.022860586643218994,\n",
       "  0.04789486154913902,\n",
       "  -0.027205942198634148,\n",
       "  0.08771815150976181,\n",
       "  0.03364402800798416,\n",
       "  0.04555254057049751,\n",
       "  -0.09400688111782074,\n",
       "  0.004392407368868589,\n",
       "  -0.0678878128528595,\n",
       "  -0.02454695664346218,\n",
       "  -0.08415841311216354,\n",
       "  0.06484068930149078,\n",
       "  -0.04490656405687332,\n",
       "  -0.009450308978557587,\n",
       "  0.08019720762968063,\n",
       "  -0.022047286853194237,\n",
       "  0.032102350145578384,\n",
       "  0.003303101286292076,\n",
       "  0.0729653537273407,\n",
       "  -0.05635155737400055,\n",
       "  0.04670966789126396,\n",
       "  -7.053845507698497e-08,\n",
       "  -0.018475068733096123,\n",
       "  -0.02198086306452751,\n",
       "  0.04243315011262894,\n",
       "  0.03493761643767357,\n",
       "  -0.004665770567953587,\n",
       "  -0.06231841817498207,\n",
       "  -0.03748498484492302,\n",
       "  -0.07988172769546509,\n",
       "  -0.018364107236266136,\n",
       "  -0.041859690099954605,\n",
       "  -0.047496944665908813,\n",
       "  0.08763638138771057,\n",
       "  -0.011307376436889172,\n",
       "  -0.008952231146395206,\n",
       "  -0.038958121091127396,\n",
       "  -0.034082114696502686,\n",
       "  0.01918162778019905,\n",
       "  0.08975673466920853,\n",
       "  -0.002174695720896125,\n",
       "  0.01822265051305294,\n",
       "  0.05337989330291748,\n",
       "  -0.021762294694781303,\n",
       "  -0.04218504950404167,\n",
       "  -0.031826578080654144,\n",
       "  -0.0759073868393898,\n",
       "  -0.07043898105621338,\n",
       "  -0.02801607921719551,\n",
       "  -0.06508909165859222,\n",
       "  -0.09373690187931061,\n",
       "  -0.013963140547275543,\n",
       "  0.034804604947566986,\n",
       "  -0.022159568965435028,\n",
       "  0.06830169260501862,\n",
       "  -0.10551365464925766,\n",
       "  0.03405466675758362,\n",
       "  -0.01850830391049385,\n",
       "  0.01490139588713646,\n",
       "  0.03759969398379326,\n",
       "  -0.0845981165766716,\n",
       "  -0.039636798202991486,\n",
       "  -0.028673067688941956,\n",
       "  0.06124870106577873,\n",
       "  0.07304317504167557,\n",
       "  -0.031762052327394485,\n",
       "  0.05989135056734085,\n",
       "  0.03226593881845474,\n",
       "  0.011064667254686356,\n",
       "  -0.027190014719963074,\n",
       "  -0.016942603513598442,\n",
       "  -0.023867318406701088,\n",
       "  -0.04612921550869942,\n",
       "  0.07624717801809311,\n",
       "  0.07048746198415756,\n",
       "  -0.011641845107078552,\n",
       "  -0.0548027902841568,\n",
       "  0.06928663700819016,\n",
       "  0.021747324615716934,\n",
       "  0.006312282755970955,\n",
       "  -0.05577422305941582,\n",
       "  0.01436892244964838,\n",
       "  0.004704930819571018,\n",
       "  -0.06110138073563576,\n",
       "  -0.02787913754582405,\n",
       "  0.03289659693837166],\n",
       " 'payload': {'content': 'giochi olimpici moderna evento sportivo quadriennale prevede competizione migliori atleti mondo quasi tutte discipline sportive praticate cinque continenti abitati essi pur comunemente chiamati olimpiadi confondere olimpiade quest ultima indica intervallo tempo quattro anni intercorre edizione giochi olimpici estivi successiva giochi 1916 1940 1944 stati disputati continuato conteggiare olimpiadi cosicché giochi parigi 2024 stati trentatreesima edizione nome giochi olimpici stato scelto ricordare giochi olimpici antichi svolgevano antica grecia onore presso città olimpia quali sfidavano migliori atleti greci barone pierre coubertin fine xix secolo idea organizzare giochi simili antica grecia quindi preclusi genere femminile punto venne ascoltato prime olimpiadi moderna svolsero atene 1896 partire 1924 vennero istituiti giochi olimpici specifici sport invernali esistono paralimpiadi competizioni persone disabili 1994 edizione invernale tiene stesso anno estiva sfalsata due anni bandiera',\n",
       "  'language': 'it',\n",
       "  'title': 'Giochi_olimpici',\n",
       "  'url': 'https://it.wikipedia.org/wiki/Giochi_olimpici'}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_chunk_to_json(chunk, output_dir):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate a filename using the chunk ID\n",
    "    filename = f\"{chunk['id']}.json\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    # Write the chunk to a JSON file\n",
    "    with open(filepath, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(chunk, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Chunk saved as {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk saved as chunked_documents\\9bcca9b1-76dd-4597-9ecd-7aae8e62d085.json\n",
      "Chunk saved as chunked_documents\\0164dfd0-beae-46bf-9da1-6e4e3022ad8c.json\n",
      "Chunk saved as chunked_documents\\c185fd48-53ea-4285-a51f-3765a990f0e1.json\n",
      "Chunk saved as chunked_documents\\a9793504-9151-4458-86ac-0df6fb0edf7f.json\n",
      "Chunk saved as chunked_documents\\497af23b-fb58-476e-b443-06d3343e89f5.json\n",
      "Chunk saved as chunked_documents\\44d2854c-7e9f-4075-a337-7cdfc9238d10.json\n",
      "Chunk saved as chunked_documents\\2bee4bdc-33a5-466f-a4dc-e6c2d3fea385.json\n",
      "Chunk saved as chunked_documents\\070c7a2e-abb4-4c5a-b32e-d5de455eab38.json\n",
      "Chunk saved as chunked_documents\\73ac319c-96b9-42b7-81d5-d9fff8913c04.json\n",
      "Chunk saved as chunked_documents\\b94b4d5d-db88-47be-b795-416d2d107bcd.json\n",
      "Chunk saved as chunked_documents\\cd451ddd-5a19-4ed7-9905-71b3d3b6107d.json\n",
      "Chunk saved as chunked_documents\\083c776b-f0e2-4464-88ce-6f19461e1eaf.json\n",
      "Chunk saved as chunked_documents\\465f9c67-df80-435b-8df3-9e63c7183d9b.json\n",
      "Chunk saved as chunked_documents\\70752b75-5a92-49c5-8717-81235debb3cf.json\n",
      "Chunk saved as chunked_documents\\ea11017d-6713-48aa-ac30-da3268af0b7c.json\n",
      "Chunk saved as chunked_documents\\8e2a9a3e-8f9f-4cc5-b0b3-b97f5e8e979e.json\n",
      "Chunk saved as chunked_documents\\03325c45-e6aa-485e-abea-6f446da7dce3.json\n",
      "Chunk saved as chunked_documents\\f4ab93df-3ae8-4978-b9ca-8cb4367e2a5e.json\n",
      "Chunk saved as chunked_documents\\bee4910a-603c-4a98-9176-d47e5e1c39b5.json\n",
      "Chunk saved as chunked_documents\\84590876-038c-473d-b225-f7a3605405eb.json\n",
      "Chunk saved as chunked_documents\\7c371399-c76a-4cc7-be44-7c38a1684851.json\n",
      "Chunk saved as chunked_documents\\6e27d10f-ca3b-4ef7-8127-9b7c0ee45d5a.json\n",
      "Chunk saved as chunked_documents\\f26f2799-45d5-4c54-86a0-35378fa6ae9c.json\n",
      "Chunk saved as chunked_documents\\9f46c927-e4da-4ce3-b9a1-f869a8775e8f.json\n",
      "Chunk saved as chunked_documents\\680a1ba1-21bf-4bce-a173-4291f4540299.json\n",
      "Chunk saved as chunked_documents\\72b505c7-be5d-4679-a40e-eea0df7ba78e.json\n",
      "Chunk saved as chunked_documents\\8fbd836a-ab92-45a6-b2da-8e6b9d2618f1.json\n",
      "Chunk saved as chunked_documents\\df8905b7-3baf-45ea-aea5-0627506d9f43.json\n",
      "Chunk saved as chunked_documents\\4a85743f-16f1-4273-bb66-335d41f496bb.json\n",
      "Chunk saved as chunked_documents\\c5801a43-4b3f-4140-ad6f-593d0bf0a2c3.json\n",
      "Chunk saved as chunked_documents\\85be3d74-7667-41c9-a4df-2d9a2bc9e251.json\n",
      "Chunk saved as chunked_documents\\ff6ce9fb-b8df-4893-88c6-ccba6f7fc451.json\n",
      "Chunk saved as chunked_documents\\01a7234f-3198-42a6-a101-e3bd90dd56e8.json\n",
      "Chunk saved as chunked_documents\\dfe65fe0-4451-46d0-ac31-7582f48060d9.json\n",
      "Chunk saved as chunked_documents\\b3df416d-6343-4270-9862-f7693642bbfe.json\n",
      "Chunk saved as chunked_documents\\0778d780-b2e4-40e9-827d-41afd8087ad0.json\n",
      "Chunk saved as chunked_documents\\10344e99-32d1-4242-8eed-80aeaa2fb67f.json\n",
      "Chunk saved as chunked_documents\\78642ab7-0ec5-4570-8bd1-3aa4e91279c5.json\n",
      "Chunk saved as chunked_documents\\32cee742-ca7b-49cf-855e-575159f233a2.json\n",
      "Chunk saved as chunked_documents\\c60cd50b-e406-44bf-82eb-33595d4f8292.json\n",
      "Chunk saved as chunked_documents\\82c7b829-fd62-43f9-812d-d87dac7bbc82.json\n",
      "Chunk saved as chunked_documents\\ed86c65b-f3f6-4f74-a923-e255f04f5ca5.json\n",
      "Chunk saved as chunked_documents\\67ced270-a62c-485f-9f96-5bac1d7d3134.json\n",
      "Chunk saved as chunked_documents\\d0410b8c-e7fa-4b73-b467-f4967e78f130.json\n",
      "Chunk saved as chunked_documents\\da8a921e-5f42-4c90-bc2a-17982cbdedcf.json\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "output_dir = 'chunked_documents'\n",
    "\n",
    "for chunk in chunks:\n",
    "    save_chunk_to_json(chunk, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the chunks as Qrant points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the official libraries from Qdrant APi\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import (\n",
    "    VectorParams,\n",
    "    Distance,\n",
    "    Filter,\n",
    "    FieldCondition,\n",
    "    MatchValue,\n",
    "    PointStruct,\n",
    "    Distance,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunks_to_qdrant(chunks_dir: str, collection_name: str):\n",
    "    # Connect to Qdrant instance\n",
    "    qdrant_client = QdrantClient(host=\"localhost\", port=6333)  # Adjust as necessary\n",
    "\n",
    "    processed_chunks = []\n",
    "    unprocessed_chunks = []\n",
    "    \n",
    "    # Create the collection if it doesn't exist\n",
    "    if not qdrant_client.collection_exists(collection_name):\n",
    "        qdrant_client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n",
    "        )\n",
    "        print(f\"Collection '{collection_name}' created in Qdrant.\")\n",
    "    else:\n",
    "        print(f\"Collection '{collection_name}' already exists in Qdrant.\")\n",
    "    \n",
    "    # Iterate over all chunk files in the directory\n",
    "    for filename in os.listdir(chunks_dir):\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(chunks_dir, filename)\n",
    "\n",
    "            print(f\"Processing file '{filename}'...\")\n",
    "\n",
    "            try:\n",
    "                with open(filepath, 'r', encoding='utf-8') as json_file:\n",
    "                    chunk = json.load(json_file)\n",
    "                    point_id = chunk['id']\n",
    "                    \n",
    "\n",
    "                    # Insert the point into Qdrant\n",
    "                    qdrant_client.upsert(\n",
    "                        collection_name=collection_name,\n",
    "                        points=[\n",
    "                            PointStruct(\n",
    "                                id=point_id,\n",
    "                                vector=chunk['vector'],\n",
    "                                payload=chunk['payload']\n",
    "                            )\n",
    "                        ]\n",
    "                    )\n",
    "                    print(f\"Point {point_id} inserted into Qdrant.\")\n",
    "                    processed_chunks.append(filepath)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file '{filename}': {e}\")\n",
    "                unprocessed_chunks.append(filepath)\n",
    "    \n",
    "    print(f\"Processed {len(processed_chunks)} chunks.\")\n",
    "    print(f\"Failed to process {len(unprocessed_chunks)} chunks.\")\n",
    "    print(f\"Failed chunks: {unprocessed_chunks}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'test_collection' already exists in Qdrant.\n",
      "Processing file '0164dfd0-beae-46bf-9da1-6e4e3022ad8c.json'...\n",
      "Point 0164dfd0-beae-46bf-9da1-6e4e3022ad8c inserted into Qdrant.\n",
      "Processing file '01a7234f-3198-42a6-a101-e3bd90dd56e8.json'...\n",
      "Point 01a7234f-3198-42a6-a101-e3bd90dd56e8 inserted into Qdrant.\n",
      "Processing file '03325c45-e6aa-485e-abea-6f446da7dce3.json'...\n",
      "Point 03325c45-e6aa-485e-abea-6f446da7dce3 inserted into Qdrant.\n",
      "Processing file '070c7a2e-abb4-4c5a-b32e-d5de455eab38.json'...\n",
      "Point 070c7a2e-abb4-4c5a-b32e-d5de455eab38 inserted into Qdrant.\n",
      "Processing file '0778d780-b2e4-40e9-827d-41afd8087ad0.json'...\n",
      "Point 0778d780-b2e4-40e9-827d-41afd8087ad0 inserted into Qdrant.\n",
      "Processing file '083c776b-f0e2-4464-88ce-6f19461e1eaf.json'...\n",
      "Point 083c776b-f0e2-4464-88ce-6f19461e1eaf inserted into Qdrant.\n",
      "Processing file '10344e99-32d1-4242-8eed-80aeaa2fb67f.json'...\n",
      "Point 10344e99-32d1-4242-8eed-80aeaa2fb67f inserted into Qdrant.\n",
      "Processing file '2bee4bdc-33a5-466f-a4dc-e6c2d3fea385.json'...\n",
      "Point 2bee4bdc-33a5-466f-a4dc-e6c2d3fea385 inserted into Qdrant.\n",
      "Processing file '32cee742-ca7b-49cf-855e-575159f233a2.json'...\n",
      "Point 32cee742-ca7b-49cf-855e-575159f233a2 inserted into Qdrant.\n",
      "Processing file '44d2854c-7e9f-4075-a337-7cdfc9238d10.json'...\n",
      "Point 44d2854c-7e9f-4075-a337-7cdfc9238d10 inserted into Qdrant.\n",
      "Processing file '465f9c67-df80-435b-8df3-9e63c7183d9b.json'...\n",
      "Point 465f9c67-df80-435b-8df3-9e63c7183d9b inserted into Qdrant.\n",
      "Processing file '497af23b-fb58-476e-b443-06d3343e89f5.json'...\n",
      "Point 497af23b-fb58-476e-b443-06d3343e89f5 inserted into Qdrant.\n",
      "Processing file '4a85743f-16f1-4273-bb66-335d41f496bb.json'...\n",
      "Point 4a85743f-16f1-4273-bb66-335d41f496bb inserted into Qdrant.\n",
      "Processing file '59dfa185-dae1-4cb9-8cc3-8c63fd437478.json'...\n",
      "Error processing file '59dfa185-dae1-4cb9-8cc3-8c63fd437478.json': Expecting value: line 3 column 15 (char 66)\n",
      "Processing file '67ced270-a62c-485f-9f96-5bac1d7d3134.json'...\n",
      "Point 67ced270-a62c-485f-9f96-5bac1d7d3134 inserted into Qdrant.\n",
      "Processing file '680a1ba1-21bf-4bce-a173-4291f4540299.json'...\n",
      "Point 680a1ba1-21bf-4bce-a173-4291f4540299 inserted into Qdrant.\n",
      "Processing file '6e27d10f-ca3b-4ef7-8127-9b7c0ee45d5a.json'...\n",
      "Point 6e27d10f-ca3b-4ef7-8127-9b7c0ee45d5a inserted into Qdrant.\n",
      "Processing file '70752b75-5a92-49c5-8717-81235debb3cf.json'...\n",
      "Point 70752b75-5a92-49c5-8717-81235debb3cf inserted into Qdrant.\n",
      "Processing file '72b505c7-be5d-4679-a40e-eea0df7ba78e.json'...\n",
      "Point 72b505c7-be5d-4679-a40e-eea0df7ba78e inserted into Qdrant.\n",
      "Processing file '73ac319c-96b9-42b7-81d5-d9fff8913c04.json'...\n",
      "Point 73ac319c-96b9-42b7-81d5-d9fff8913c04 inserted into Qdrant.\n",
      "Processing file '78642ab7-0ec5-4570-8bd1-3aa4e91279c5.json'...\n",
      "Point 78642ab7-0ec5-4570-8bd1-3aa4e91279c5 inserted into Qdrant.\n",
      "Processing file '7c371399-c76a-4cc7-be44-7c38a1684851.json'...\n",
      "Point 7c371399-c76a-4cc7-be44-7c38a1684851 inserted into Qdrant.\n",
      "Processing file '82c7b829-fd62-43f9-812d-d87dac7bbc82.json'...\n",
      "Point 82c7b829-fd62-43f9-812d-d87dac7bbc82 inserted into Qdrant.\n",
      "Processing file '84590876-038c-473d-b225-f7a3605405eb.json'...\n",
      "Point 84590876-038c-473d-b225-f7a3605405eb inserted into Qdrant.\n",
      "Processing file '85be3d74-7667-41c9-a4df-2d9a2bc9e251.json'...\n",
      "Point 85be3d74-7667-41c9-a4df-2d9a2bc9e251 inserted into Qdrant.\n",
      "Processing file '8e2a9a3e-8f9f-4cc5-b0b3-b97f5e8e979e.json'...\n",
      "Point 8e2a9a3e-8f9f-4cc5-b0b3-b97f5e8e979e inserted into Qdrant.\n",
      "Processing file '8fbd836a-ab92-45a6-b2da-8e6b9d2618f1.json'...\n",
      "Point 8fbd836a-ab92-45a6-b2da-8e6b9d2618f1 inserted into Qdrant.\n",
      "Processing file '9bcca9b1-76dd-4597-9ecd-7aae8e62d085.json'...\n",
      "Point 9bcca9b1-76dd-4597-9ecd-7aae8e62d085 inserted into Qdrant.\n",
      "Processing file '9f46c927-e4da-4ce3-b9a1-f869a8775e8f.json'...\n",
      "Point 9f46c927-e4da-4ce3-b9a1-f869a8775e8f inserted into Qdrant.\n",
      "Processing file 'a9793504-9151-4458-86ac-0df6fb0edf7f.json'...\n",
      "Point a9793504-9151-4458-86ac-0df6fb0edf7f inserted into Qdrant.\n",
      "Processing file 'b3df416d-6343-4270-9862-f7693642bbfe.json'...\n",
      "Point b3df416d-6343-4270-9862-f7693642bbfe inserted into Qdrant.\n",
      "Processing file 'b94b4d5d-db88-47be-b795-416d2d107bcd.json'...\n",
      "Point b94b4d5d-db88-47be-b795-416d2d107bcd inserted into Qdrant.\n",
      "Processing file 'bee4910a-603c-4a98-9176-d47e5e1c39b5.json'...\n",
      "Point bee4910a-603c-4a98-9176-d47e5e1c39b5 inserted into Qdrant.\n",
      "Processing file 'c185fd48-53ea-4285-a51f-3765a990f0e1.json'...\n",
      "Point c185fd48-53ea-4285-a51f-3765a990f0e1 inserted into Qdrant.\n",
      "Processing file 'c5801a43-4b3f-4140-ad6f-593d0bf0a2c3.json'...\n",
      "Point c5801a43-4b3f-4140-ad6f-593d0bf0a2c3 inserted into Qdrant.\n",
      "Processing file 'c60cd50b-e406-44bf-82eb-33595d4f8292.json'...\n",
      "Point c60cd50b-e406-44bf-82eb-33595d4f8292 inserted into Qdrant.\n",
      "Processing file 'cd451ddd-5a19-4ed7-9905-71b3d3b6107d.json'...\n",
      "Point cd451ddd-5a19-4ed7-9905-71b3d3b6107d inserted into Qdrant.\n",
      "Processing file 'd0410b8c-e7fa-4b73-b467-f4967e78f130.json'...\n",
      "Point d0410b8c-e7fa-4b73-b467-f4967e78f130 inserted into Qdrant.\n",
      "Processing file 'da8a921e-5f42-4c90-bc2a-17982cbdedcf.json'...\n",
      "Point da8a921e-5f42-4c90-bc2a-17982cbdedcf inserted into Qdrant.\n",
      "Processing file 'df8905b7-3baf-45ea-aea5-0627506d9f43.json'...\n",
      "Point df8905b7-3baf-45ea-aea5-0627506d9f43 inserted into Qdrant.\n",
      "Processing file 'dfe65fe0-4451-46d0-ac31-7582f48060d9.json'...\n",
      "Point dfe65fe0-4451-46d0-ac31-7582f48060d9 inserted into Qdrant.\n",
      "Processing file 'ea11017d-6713-48aa-ac30-da3268af0b7c.json'...\n",
      "Point ea11017d-6713-48aa-ac30-da3268af0b7c inserted into Qdrant.\n",
      "Processing file 'ed86c65b-f3f6-4f74-a923-e255f04f5ca5.json'...\n",
      "Point ed86c65b-f3f6-4f74-a923-e255f04f5ca5 inserted into Qdrant.\n",
      "Processing file 'f26f2799-45d5-4c54-86a0-35378fa6ae9c.json'...\n",
      "Point f26f2799-45d5-4c54-86a0-35378fa6ae9c inserted into Qdrant.\n",
      "Processing file 'f4ab93df-3ae8-4978-b9ca-8cb4367e2a5e.json'...\n",
      "Point f4ab93df-3ae8-4978-b9ca-8cb4367e2a5e inserted into Qdrant.\n",
      "Processing file 'ff6ce9fb-b8df-4893-88c6-ccba6f7fc451.json'...\n",
      "Point ff6ce9fb-b8df-4893-88c6-ccba6f7fc451 inserted into Qdrant.\n",
      "Processed 45 chunks.\n",
      "Failed to process 1 chunks.\n",
      "Failed chunks: ['chunked_documents\\\\59dfa185-dae1-4cb9-8cc3-8c63fd437478.json']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "chunks_dir = 'chunked_documents'\n",
    "collection_name = 'test_collection'\n",
    "\n",
    "# Load chunks into Qdrant\n",
    "load_chunks_to_qdrant(chunks_dir, collection_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
